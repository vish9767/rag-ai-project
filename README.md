# ğŸ§  RAG AI - Retrieval-Augmented Generation from PDFs

This project implements a **Retrieval-Augmented Generation (RAG)** pipeline using LangChain, OpenAI, and Pinecone to answer questions from the content of a PDF document.

It allows you to load a PDF file, split it into chunks, embed the text using OpenAI's embedding models, store and retrieve it from a Pinecone vector database, and then generate accurate answers using a large language model (LLM).

---

## ğŸš€ Features

- ğŸ“„ Load and parse PDFs using `langchain_community.document_loaders.PyPDFLoader`
- âœ‚ï¸ Split documents into chunks using `RecursiveCharacterTextSplitter`
- ğŸ” Embed chunks with `OpenAIEmbeddings`
- ğŸ§  Store and search embeddings using `PineconeVectorStore`
- ğŸ¤– Answer questions with `ChatOpenAI` using context retrieved from PDF
- ğŸª„ Uses RAG (Retrieval-Augmented Generation) technique
- âš¡ Asynchronous and optimized for speed with Pinecone multithreaded indexing

---

## ğŸ“¦ Tech Stack

| Tool         | Purpose                             |
|--------------|-------------------------------------|
| LangChain    | Framework for RAG pipelines         |
| OpenAI       | Embeddings + ChatGPT LLM            |
| Pinecone     | Vector database for semantic search |
| PyPDFLoader  | PDF document parsing                |
| Python       | Language used                       |

---

## ğŸ“ Folder Structure (Optional Example)


rag-ai-project/
â”‚
â”œâ”€â”€ rag_app.py # Main script (your code)
â”œâ”€â”€ requirements.txt # Python dependencies
â”œâ”€â”€ README.md # Project overview
â””â”€â”€ sample.pdf # Example PDF for testing



---



